/mnt/home/renjie3/miniconda3/envs/simclr/lib/python3.7/site-packages/thop/utils.py:1: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working
  from collections import Iterable
2021-11-05 14:09:50,210 PyTorch Version: 1.7.1
2021-11-05 14:09:50,214 num_classes: 10
2021-11-05 14:09:50,215 epochs: 300
2021-11-05 14:09:50,215 grad_clip: 5.0
2021-11-05 14:09:50,215 log_frequency: 100
2021-11-05 14:09:50,216 model: {'name': 'ResNet18', 'num_classes': 10}
2021-11-05 14:09:50,216 criterion: {'name': 'CrossEntropyLoss'}
2021-11-05 14:09:50,216 optimizer: {'name': 'SGD', 'lr': 0.1, 'weight_decay': 0.0005, 'momentum': 0.9}
2021-11-05 14:09:50,216 scheduler: {'name': 'CosineAnnealingLR', 'T_max': 300, 'eta_min': 0.0}
2021-11-05 14:09:50,217 dataset: {'name': 'DatasetGenerator', 'train_batch_size': 128, 'eval_batch_size': 128}
2021-11-05 14:09:50,218 seed: 0
2021-11-05 14:09:50,219 version: resnet18
2021-11-05 14:09:50,219 exp_name: my_experiments/class_wise_cifar10_random_assign_32_10_0.8
2021-11-05 14:09:50,219 config_path: configs/cifar10
2021-11-05 14:09:50,220 load_model: False
2021-11-05 14:09:50,220 data_parallel: False
2021-11-05 14:09:50,220 train_batch_size: 512
2021-11-05 14:09:50,220 eval_batch_size: 512
2021-11-05 14:09:50,220 num_of_workers: 8
2021-11-05 14:09:50,221 train_data_type: CIFAR10
2021-11-05 14:09:50,221 train_data_path: ../datasets
2021-11-05 14:09:50,221 test_data_type: CIFAR10
2021-11-05 14:09:50,222 test_data_path: ../datasets
2021-11-05 14:09:50,222 universal_train_portion: 0.2
2021-11-05 14:09:50,222 universal_stop_error: 0.1
2021-11-05 14:09:50,222 universal_train_target: 'train_dataset'
2021-11-05 14:09:50,223 train_step: 10
2021-11-05 14:09:50,223 use_subset: False
2021-11-05 14:09:50,223 attack_type: min-min
2021-11-05 14:09:50,223 perturb_type: classwise
2021-11-05 14:09:50,223 patch_location: center
2021-11-05 14:09:50,224 noise_shape: [10, 3, 32, 32]
2021-11-05 14:09:50,224 epsilon: 0.12549019607843137
2021-11-05 14:09:50,224 num_steps: 10
2021-11-05 14:09:50,224 step_size: 0.0031372549019607846
2021-11-05 14:09:50,225 random_start: False
2021-11-05 14:09:50,225 job_id: 103478009
2021-11-05 14:09:51,985 param size = 11.173962MB
2021-11-05 14:09:54,028 ====================Searching Universal Perturbation====================
Traceback (most recent call last):
  File "perturbation.py", line 493, in <module>
    main()
  File "perturbation.py", line 479, in main
    noise = universal_perturbation(noise_generator, trainer, evaluator, model, criterion, optimizer, scheduler, random_noise, ENV)
  File "perturbation.py", line 198, in universal_perturbation
    for i, (images, labels) in tqdm(enumerate(data_loader[args.universal_train_target]), total=len(data_loader[args.universal_train_target])):
KeyError: "'train_dataset'"

New small dataset
python3 -u ssl_perturbation_save_model_random_noise.py --config_path configs/cifar10 --exp_name path/to/your/experiment/folder --version resnet18 --train_data_type CIFAR10 --noise_shape 4 3 32 32 --epsilon 32 --num_steps 10 --step_size 3.2 --attack_type min-min --perturb_type classwise --universal_train_target 'classwise' --train_step 10 --epochs 1000 --min_min_attack_fn non_eot --strong_aug --random_start
check check
__name__ simclr
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
tensor([[[[ 0.0632,  0.0928, -0.0477,  ..., -0.0404,  0.0198, -0.0730],
          [-0.0812,  0.1254,  0.0692,  ...,  0.0495,  0.0861,  0.0348],
          [ 0.0927,  0.0921,  0.0825,  ...,  0.0717,  0.0525,  0.0021],
          ...,
          [ 0.0655,  0.0804, -0.1139,  ..., -0.0643,  0.0017, -0.1012],
          [ 0.0419, -0.0931,  0.1174,  ...,  0.0251,  0.0578, -0.0199],
          [ 0.0629,  0.0077, -0.1163,  ...,  0.0786, -0.1121,  0.0112]],

         [[ 0.0311, -0.0625, -0.1123,  ...,  0.0208,  0.0580, -0.1167],
          [-0.0096,  0.1180, -0.0515,  ...,  0.0936,  0.1241,  0.1217],
          [ 0.0617,  0.0592,  0.0774,  ..., -0.1215, -0.1043, -0.0863],
          ...,
          [-0.0499,  0.1240, -0.1125,  ..., -0.0916, -0.0076,  0.0374],
          [-0.1149,  0.0142,  0.0879,  ...,  0.1097, -0.1183,  0.1217],
          [-0.0283, -0.0872,  0.0231,  ..., -0.0830, -0.0127,  0.0574]],

         [[ 0.0218,  0.0431,  0.1067,  ...,  0.0367,  0.0244,  0.0267],
          [ 0.0936, -0.0299, -0.0350,  ...,  0.0981,  0.0416,  0.0550],
          [-0.0529,  0.1030, -0.0212,  ..., -0.0584, -0.0258,  0.0497],
          ...,
          [-0.1221,  0.0771, -0.0149,  ..., -0.0555, -0.0303, -0.0468],
          [ 0.0156,  0.0709,  0.1046,  ...,  0.0316,  0.0435,  0.0316],
          [-0.0226,  0.1186, -0.0415,  ...,  0.0572,  0.0984,  0.0690]]],


        [[[ 0.0911,  0.0012,  0.0931,  ...,  0.0904, -0.0633,  0.0390],
          [-0.0376,  0.0939,  0.0482,  ...,  0.0052,  0.0509,  0.0145],
          [ 0.0529,  0.1039,  0.0613,  ...,  0.0182,  0.0982, -0.0095],
          ...,
          [ 0.1100,  0.0561, -0.0651,  ..., -0.0253, -0.0452,  0.1219],
          [ 0.0677,  0.0859,  0.1092,  ..., -0.0640,  0.1104,  0.0497],
          [ 0.0123, -0.0012,  0.0211,  ...,  0.1234, -0.1078, -0.0233]],

         [[ 0.1167,  0.1040, -0.1131,  ..., -0.0874, -0.0788,  0.0043],
          [-0.0576, -0.0406,  0.0722,  ...,  0.1058, -0.1215,  0.0549],
          [ 0.0773,  0.0538, -0.0234,  ...,  0.0948,  0.0133,  0.0253],
          ...,
          [-0.0805,  0.0572, -0.1212,  ..., -0.0617,  0.0982,  0.0604],
          [-0.0014,  0.0616, -0.1024,  ...,  0.0802,  0.0624, -0.1026],
          [-0.1154,  0.0091,  0.0684,  ..., -0.0700, -0.1197, -0.0123]],

         [[-0.0251,  0.0566,  0.0233,  ...,  0.0921, -0.0924,  0.0276],
          [-0.0112,  0.1022,  0.0789,  ..., -0.0626,  0.0203,  0.0924],
          [ 0.0764,  0.1151, -0.0300,  ...,  0.0079,  0.1156, -0.0857],
          ...,
          [-0.0887, -0.0284,  0.0324,  ...,  0.0680,  0.0578, -0.0173],
          [-0.0430,  0.1034,  0.0822,  ...,  0.0765, -0.0741, -0.0704],
          [-0.0720, -0.0466, -0.0274,  ..., -0.1072,  0.1164,  0.0161]]],


        [[[-0.0997,  0.0307, -0.0576,  ...,  0.0981,  0.0777,  0.0164],
          [-0.0581, -0.0743,  0.0679,  ...,  0.0069,  0.0048, -0.1201],
          [ 0.1119,  0.1173,  0.0739,  ...,  0.0344, -0.0761, -0.0465],
          ...,
          [-0.0071, -0.0766, -0.0321,  ..., -0.0318, -0.0169, -0.0163],
          [-0.1180,  0.0167, -0.0272,  ..., -0.1138, -0.1127, -0.0496],
          [ 0.0279,  0.0688, -0.0523,  ..., -0.0282,  0.1111,  0.0545]],

         [[ 0.0528, -0.0223,  0.0995,  ..., -0.0659, -0.0410,  0.0227],
          [ 0.0533,  0.0380, -0.0124,  ..., -0.0099, -0.1243,  0.0312],
          [-0.0623, -0.0186, -0.0379,  ..., -0.0185,  0.0011, -0.0862],
          ...,
          [-0.1160,  0.0929, -0.1223,  ...,  0.0014,  0.1053, -0.0438],
          [-0.0199, -0.0474, -0.0907,  ..., -0.0347, -0.1156,  0.0580],
          [ 0.0319, -0.0622,  0.1219,  ..., -0.0975,  0.1246,  0.1089]],

         [[ 0.0172,  0.1040, -0.1050,  ..., -0.0824, -0.0881, -0.0311],
          [ 0.0966, -0.0862,  0.0091,  ...,  0.1061,  0.1159,  0.0854],
          [-0.0111,  0.0017,  0.0255,  ...,  0.0471,  0.0273,  0.0515],
          ...,
          [-0.0915,  0.0439,  0.1224,  ...,  0.1233, -0.1184,  0.0480],
          [-0.1027,  0.0777, -0.1245,  ...,  0.1031,  0.0155,  0.0187],
          [ 0.0331, -0.0692, -0.0579,  ..., -0.0883,  0.0634, -0.0026]]],


        [[[ 0.1001, -0.0370, -0.0276,  ..., -0.1233, -0.0852, -0.0817],
          [-0.0287,  0.0747,  0.0964,  ..., -0.0166,  0.1199, -0.0687],
          [ 0.0306, -0.0507, -0.0066,  ..., -0.0828,  0.1047,  0.0659],
          ...,
          [ 0.0713, -0.0600,  0.0039,  ...,  0.1149,  0.0006,  0.1098],
          [ 0.0921, -0.1089, -0.0762,  ..., -0.0093, -0.0892, -0.0895],
          [-0.0746,  0.0833, -0.0823,  ...,  0.1201, -0.0969, -0.0709]],

         [[-0.0410, -0.0593, -0.0611,  ..., -0.0464,  0.0428,  0.0239],
          [ 0.0186, -0.0624, -0.0595,  ..., -0.0278, -0.1094,  0.0874],
          [-0.1222, -0.0585,  0.0623,  ...,  0.1068, -0.0081,  0.0825],
          ...,
          [-0.1191,  0.1224, -0.0773,  ..., -0.0785,  0.0806, -0.0895],
          [-0.1152,  0.0044,  0.0680,  ...,  0.0346, -0.0555,  0.0653],
          [ 0.0836,  0.0064, -0.1090,  ...,  0.0137, -0.1045,  0.0365]],

         [[ 0.0703, -0.0592, -0.0259,  ..., -0.0513, -0.0932,  0.0349],
          [-0.0646, -0.1249,  0.0107,  ..., -0.1198,  0.0926,  0.1074],
          [-0.0675, -0.0741,  0.1242,  ...,  0.0409, -0.0162,  0.0036],
          ...,
          [-0.0367, -0.0264,  0.0354,  ...,  0.0825,  0.1152,  0.0542],
          [ 0.0276,  0.0151, -0.0545,  ..., -0.0021,  0.0116,  0.0609],
          [-0.0885,  0.0950, -0.0954,  ..., -0.0911, -0.0114,  0.0706]]]],
       device='cuda:0')
The whole epochs are 1000
6.943230390548706
6.883881330490112
6.860011577606201
6.803136348724365
6.784888744354248
6.797705173492432
6.807554006576538
6.823761224746704
6.781196117401123
6.804685831069946
model saved at unlearnable_20211031214814_0.5_512_1000
6.7938551902771
6.761355876922607
6.780249834060669
6.787914752960205
6.771271705627441
6.793676376342773
6.757983922958374
6.7529966831207275
6.763546466827393
6.773160219192505
model saved at unlearnable_20211031214814_0.5_512_1000
6.7451491355896
6.7706520557403564
6.74373722076416
6.742348909378052
6.752145767211914
6.724229574203491
6.725341320037842
6.789561033248901
6.748384714126587
6.767715215682983
model saved at unlearnable_20211031214814_0.5_512_1000
6.744359016418457
6.729557275772095
6.7406439781188965
6.747750759124756
6.789796829223633
6.721867561340332
6.742863416671753
6.7169623374938965
6.728741884231567
6.685401916503906
model saved at unlearnable_20211031214814_0.5_512_1000
6.721461057662964
6.692582130432129
6.705697298049927
6.654428482055664
6.724717140197754
6.6797709465026855
6.727834701538086
6.709481239318848
6.670654773712158
6.70849084854126
model saved at unlearnable_20211031214814_0.5_512_1000
6.6484129428863525
6.704419374465942
6.656507968902588
6.659067630767822
6.651349067687988
6.692776203155518
6.641688823699951
6.6476593017578125
6.695769309997559
6.654264450073242
model saved at unlearnable_20211031214814_0.5_512_1000
6.615956783294678
6.611001491546631
6.617095470428467
6.642281532287598
6.6268630027771
6.6897923946380615
6.678950309753418
6.622671127319336
6.65466046333313
6.613701581954956
model saved at unlearnable_20211031214814_0.5_512_1000
6.635803461074829
6.590125560760498
6.58790922164917
6.618982315063477
6.628503322601318
6.633313417434692
6.641958951950073
6.586716651916504
6.574682950973511
6.580543756484985
model saved at unlearnable_20211031214814_0.5_512_1000
6.5796027183532715
6.648096084594727
6.568040609359741
6.5597429275512695
6.561256647109985
6.576339244842529
6.527055740356445
6.524134397506714
6.555061340332031
6.56738018989563
model saved at unlearnable_20211031214814_0.5_512_1000
6.574018478393555
6.555325031280518
6.5331339836120605
6.540013313293457
6.57218337059021
6.574159622192383
6.5721046924591064
6.536854267120361
6.551458120346069
6.567197322845459
model saved at unlearnable_20211031214814_0.5_512_1000
6.530273199081421
6.532426595687866
6.535057783126831
6.535131454467773
6.555571556091309
6.534123420715332
6.505234003067017
6.538486957550049
6.518919467926025
6.5306396484375
model saved at unlearnable_20211031214814_0.5_512_1000
6.4973649978637695
6.49652361869812
6.52790379524231
6.503390073776245
6.505700349807739
6.512601137161255
6.511881113052368
6.535084962844849
6.509397983551025
6.517673015594482
model saved at unlearnable_20211031214814_0.5_512_1000
6.526389122009277
6.476058483123779
6.521867275238037
6.502862453460693
6.48496413230896
6.5301408767700195
6.479121446609497
6.44931173324585
6.470623254776001
6.4593517780303955
model saved at unlearnable_20211031214814_0.5_512_1000
6.432104825973511
6.437591791152954
6.425959348678589
6.464505195617676
6.452715873718262
6.471590995788574
6.391343116760254
6.466532230377197
6.4148664474487305
6.416100025177002
model saved at unlearnable_20211031214814_0.5_512_1000
6.467795372009277
6.475133657455444
6.461287975311279
6.4763712882995605
6.4479875564575195
6.437033653259277
6.444425344467163
6.437865972518921
6.461252212524414
6.450932025909424
model saved at unlearnable_20211031214814_0.5_512_1000
6.429880619049072
6.442290782928467
6.4702067375183105
6.375610113143921
6.392224311828613
6.469439506530762
6.437732219696045
6.456072568893433
6.384423494338989
6.4234983921051025
model saved at unlearnable_20211031214814_0.5_512_1000
6.449527025222778
6.394355297088623
6.489772081375122
6.472545623779297
6.405142545700073
6.430288076400757
6.407766819000244
6.428923845291138
6.440369606018066
6.399266242980957
model saved at unlearnable_20211031214814_0.5_512_1000
6.391808032989502
6.420925855636597
6.403262138366699
6.4310479164123535
6.4072113037109375
6.408968925476074
6.398311376571655
6.4655921459198
6.440866708755493
6.411240339279175
model saved at unlearnable_20211031214814_0.5_512_1000
6.35661244392395
6.4057135581970215
6.398159742355347
6.414917230606079
6.432032823562622
6.397140979766846
6.385581970214844
6.36001181602478
6.381617069244385
6.373242139816284
model saved at unlearnable_20211031214814_0.5_512_1000
6.407412767410278
6.378934383392334
6.404556751251221
6.378119707107544
6.397791147232056
6.37997031211853
6.366195201873779
6.3539135456085205
6.36469030380249
6.39792799949646
model saved at unlearnable_20211031214814_0.5_512_1000
6.409392356872559
6.4033122062683105
6.370047330856323
6.393577814102173
6.381637096405029
6.364848852157593
6.353515148162842
6.380804777145386
6.372105836868286
6.381732702255249
model saved at unlearnable_20211031214814_0.5_512_1000
6.322295427322388
6.369670152664185
6.394652605056763
6.376233100891113
6.357697010040283
6.360610485076904
6.356232166290283
6.365471601486206
6.322603464126587
6.327142953872681
model saved at unlearnable_20211031214814_0.5_512_1000
6.372455596923828
6.364599704742432
6.398207426071167
6.3436174392700195
6.368185997009277
6.336146116256714
6.367166519165039
6.393167495727539
6.362570762634277
6.365880727767944
model saved at unlearnable_20211031214814_0.5_512_1000
6.359912157058716
6.396785736083984
6.326686382293701
6.337673187255859
6.298616409301758
6.369961261749268
6.329326391220093
6.35043740272522
6.379728078842163
6.353445529937744
model saved at unlearnable_20211031214814_0.5_512_1000
6.321727275848389
6.338041067123413
6.316916227340698
6.347120046615601
6.355901002883911
6.34598708152771
6.3528971672058105
6.353541135787964
6.337136507034302

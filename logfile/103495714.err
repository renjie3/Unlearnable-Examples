/mnt/home/renjie3/miniconda3/envs/simclr/lib/python3.7/site-packages/thop/utils.py:1: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working
  from collections import Iterable
2021-11-06 10:58:11,016 PyTorch Version: 1.7.1
2021-11-06 10:58:11,021 GPU List: ['Tesla V100-SXM2-32GB']
2021-11-06 10:58:11,024 num_classes: 10
2021-11-06 10:58:11,025 epochs: 300
2021-11-06 10:58:11,025 grad_clip: 5.0
2021-11-06 10:58:11,026 log_frequency: 100
2021-11-06 10:58:11,026 model: {'name': 'ResNet18', 'num_classes': 10}
2021-11-06 10:58:11,026 criterion: {'name': 'CrossEntropyLoss'}
2021-11-06 10:58:11,027 optimizer: {'name': 'SGD', 'lr': 0.1, 'weight_decay': 0.0005, 'momentum': 0.9}
2021-11-06 10:58:11,027 scheduler: {'name': 'CosineAnnealingLR', 'T_max': 300, 'eta_min': 0.0}
2021-11-06 10:58:11,027 dataset: {'name': 'DatasetGenerator', 'train_batch_size': 128, 'eval_batch_size': 128}
2021-11-06 10:58:11,029 seed: 0
2021-11-06 10:58:11,030 version: resnet18
2021-11-06 10:58:11,030 exp_name: my_experiments/class_wise_cifar10_random_assign_32_10_0.8
2021-11-06 10:58:11,030 config_path: configs/cifar10
2021-11-06 10:58:11,031 load_model: False
2021-11-06 10:58:11,031 data_parallel: False
2021-11-06 10:58:11,031 train_batch_size: 512
2021-11-06 10:58:11,032 eval_batch_size: 512
2021-11-06 10:58:11,032 num_of_workers: 8
2021-11-06 10:58:11,032 train_data_type: CIFAR10
2021-11-06 10:58:11,033 train_data_path: ../datasets
2021-11-06 10:58:11,033 test_data_type: CIFAR10
2021-11-06 10:58:11,033 test_data_path: ../datasets
2021-11-06 10:58:11,033 universal_train_portion: 0.2
2021-11-06 10:58:11,034 universal_stop_error: 0.1
2021-11-06 10:58:11,034 universal_train_target: 'train_dataset'
2021-11-06 10:58:11,034 train_step: 10
2021-11-06 10:58:11,034 use_subset: True
2021-11-06 10:58:11,034 attack_type: min-min
2021-11-06 10:58:11,035 perturb_type: classwise
2021-11-06 10:58:11,035 patch_location: center
2021-11-06 10:58:11,035 noise_shape: [10, 3, 32, 32]
2021-11-06 10:58:11,035 epsilon: 0.12549019607843137
2021-11-06 10:58:11,036 num_steps: 10
2021-11-06 10:58:11,036 step_size: 0.0031372549019607846
2021-11-06 10:58:11,036 random_start: False
2021-11-06 10:58:11,036 job_id: 103495714
2021-11-06 10:58:11,036 local_dev: 
2021-11-06 10:58:15,058 param size = 11.173962MB
2021-11-06 10:58:18,007 ====================Searching Universal Perturbation====================
Traceback (most recent call last):
  File "perturbation.py", line 494, in <module>
    main()
  File "perturbation.py", line 480, in main
    noise = universal_perturbation(noise_generator, trainer, evaluator, model, criterion, optimizer, scheduler, random_noise, ENV)
  File "perturbation.py", line 199, in universal_perturbation
    for i, (images, labels) in tqdm(enumerate(data_loader[args.universal_train_target]), total=len(data_loader[args.universal_train_target])):
KeyError: "'train_dataset'"

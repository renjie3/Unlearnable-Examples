/mnt/home/renjie3/miniconda3/envs/simclr/lib/python3.7/site-packages/thop/utils.py:1: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working
  from collections import Iterable
2021-11-05 14:09:58,393 PyTorch Version: 1.7.1
2021-11-05 14:09:58,409 num_classes: 10
2021-11-05 14:09:58,409 epochs: 300
2021-11-05 14:09:58,410 grad_clip: 5.0
2021-11-05 14:09:58,410 log_frequency: 100
2021-11-05 14:09:58,410 model: {'name': 'ResNet18', 'num_classes': 10}
2021-11-05 14:09:58,410 criterion: {'name': 'CrossEntropyLoss'}
2021-11-05 14:09:58,411 optimizer: {'name': 'SGD', 'lr': 0.1, 'weight_decay': 0.0005, 'momentum': 0.9}
2021-11-05 14:09:58,411 scheduler: {'name': 'CosineAnnealingLR', 'T_max': 300, 'eta_min': 0.0}
2021-11-05 14:09:58,411 dataset: {'name': 'DatasetGenerator', 'train_batch_size': 128, 'eval_batch_size': 128}
2021-11-05 14:09:58,413 seed: 0
2021-11-05 14:09:58,414 version: resnet18
2021-11-05 14:09:58,414 exp_name: my_experiments/class_wise_cifar10_random_assign_8_10_0.8
2021-11-05 14:09:58,414 config_path: configs/cifar10
2021-11-05 14:09:58,414 load_model: False
2021-11-05 14:09:58,415 data_parallel: False
2021-11-05 14:09:58,415 train_batch_size: 512
2021-11-05 14:09:58,415 eval_batch_size: 512
2021-11-05 14:09:58,415 num_of_workers: 8
2021-11-05 14:09:58,415 train_data_type: CIFAR10
2021-11-05 14:09:58,416 train_data_path: ../datasets
2021-11-05 14:09:58,416 test_data_type: CIFAR10
2021-11-05 14:09:58,416 test_data_path: ../datasets
2021-11-05 14:09:58,416 universal_train_portion: 0.2
2021-11-05 14:09:58,417 universal_stop_error: 0.1
2021-11-05 14:09:58,417 universal_train_target: 'train_dataset'
2021-11-05 14:09:58,417 train_step: 10
2021-11-05 14:09:58,417 use_subset: False
2021-11-05 14:09:58,418 attack_type: min-min
2021-11-05 14:09:58,418 perturb_type: classwise
2021-11-05 14:09:58,418 patch_location: center
2021-11-05 14:09:58,418 noise_shape: [10, 3, 32, 32]
2021-11-05 14:09:58,419 epsilon: 0.03137254901960784
2021-11-05 14:09:58,419 num_steps: 10
2021-11-05 14:09:58,419 step_size: 0.0031372549019607846
2021-11-05 14:09:58,419 random_start: False
2021-11-05 14:09:58,419 job_id: 103478010
2021-11-05 14:10:00,199 param size = 11.173962MB
2021-11-05 14:10:02,263 ====================Searching Universal Perturbation====================
Traceback (most recent call last):
  File "perturbation.py", line 493, in <module>
    main()
  File "perturbation.py", line 479, in main
    noise = universal_perturbation(noise_generator, trainer, evaluator, model, criterion, optimizer, scheduler, random_noise, ENV)
  File "perturbation.py", line 198, in universal_perturbation
    for i, (images, labels) in tqdm(enumerate(data_loader[args.universal_train_target]), total=len(data_loader[args.universal_train_target])):
KeyError: "'train_dataset'"

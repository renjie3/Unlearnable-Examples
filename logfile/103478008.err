/mnt/home/renjie3/miniconda3/envs/simclr/lib/python3.7/site-packages/thop/utils.py:1: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working
  from collections import Iterable
2021-11-05 14:09:36,072 PyTorch Version: 1.7.1
2021-11-05 14:09:36,078 num_classes: 10
2021-11-05 14:09:36,079 epochs: 300
2021-11-05 14:09:36,079 grad_clip: 5.0
2021-11-05 14:09:36,079 log_frequency: 100
2021-11-05 14:09:36,080 model: {'name': 'ResNet18', 'num_classes': 10}
2021-11-05 14:09:36,080 criterion: {'name': 'CrossEntropyLoss'}
2021-11-05 14:09:36,080 optimizer: {'name': 'SGD', 'lr': 0.1, 'weight_decay': 0.0005, 'momentum': 0.9}
2021-11-05 14:09:36,080 scheduler: {'name': 'CosineAnnealingLR', 'T_max': 300, 'eta_min': 0.0}
2021-11-05 14:09:36,081 dataset: {'name': 'DatasetGenerator', 'train_batch_size': 128, 'eval_batch_size': 128}
2021-11-05 14:09:36,086 seed: 0
2021-11-05 14:09:36,087 version: resnet18
2021-11-05 14:09:36,087 exp_name: my_experiments/class_wise_cifar10_random_assign_32_10_1.6
2021-11-05 14:09:36,087 config_path: configs/cifar10
2021-11-05 14:09:36,088 load_model: False
2021-11-05 14:09:36,088 data_parallel: False
2021-11-05 14:09:36,088 train_batch_size: 512
2021-11-05 14:09:36,089 eval_batch_size: 512
2021-11-05 14:09:36,090 num_of_workers: 8
2021-11-05 14:09:36,091 train_data_type: CIFAR10
2021-11-05 14:09:36,091 train_data_path: ../datasets
2021-11-05 14:09:36,091 test_data_type: CIFAR10
2021-11-05 14:09:36,092 test_data_path: ../datasets
2021-11-05 14:09:36,092 universal_train_portion: 0.2
2021-11-05 14:09:36,092 universal_stop_error: 0.1
2021-11-05 14:09:36,093 universal_train_target: 'train_dataset'
2021-11-05 14:09:36,093 train_step: 10
2021-11-05 14:09:36,093 use_subset: False
2021-11-05 14:09:36,093 attack_type: min-min
2021-11-05 14:09:36,094 perturb_type: classwise
2021-11-05 14:09:36,094 patch_location: center
2021-11-05 14:09:36,095 noise_shape: [10, 3, 32, 32]
2021-11-05 14:09:36,095 epsilon: 0.12549019607843137
2021-11-05 14:09:36,095 num_steps: 10
2021-11-05 14:09:36,095 step_size: 0.006274509803921569
2021-11-05 14:09:36,096 random_start: False
2021-11-05 14:09:36,096 job_id: 103478008
2021-11-05 14:09:38,158 param size = 11.173962MB
2021-11-05 14:09:40,107 ====================Searching Universal Perturbation====================
Traceback (most recent call last):
  File "perturbation.py", line 493, in <module>
    main()
  File "perturbation.py", line 479, in main
    noise = universal_perturbation(noise_generator, trainer, evaluator, model, criterion, optimizer, scheduler, random_noise, ENV)
  File "perturbation.py", line 198, in universal_perturbation
    for i, (images, labels) in tqdm(enumerate(data_loader[args.universal_train_target]), total=len(data_loader[args.universal_train_target])):
KeyError: "'train_dataset'"
